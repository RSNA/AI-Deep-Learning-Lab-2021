{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "segmentation.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RSNA/AI-Deep-Learning-Lab-2021/blob/main/sessions/object-detection-seg/segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp_ayf96vpUx"
      },
      "source": [
        "# Overview\n",
        "\n",
        "In this tutorial we will explore how to create a contract-expanding fully convolutional neural network (CNN) for segmentation of pneumonia (lung infection) from chest radiographs, the most common imaging modality used to screen for pulmonary disease. For any patient with suspected lung infection, including viral penumonia such as as COVID-19, the initial imaging exam of choice is a chest radiograph.\n",
        "\n",
        "## Workshop Links\n",
        "\n",
        "Use the following link to access materials from this workshop: https://github.com/peterchang77/dl_tutor/tree/master/workshops\n",
        "\n",
        "*Tutorials*\n",
        "\n",
        "* Introduction to Tensorflow 2.0 and Keras: https://bit.ly/2VSYaop\n",
        "* CNN for pneumonia classification: https://bit.ly/2D9ZBrX\n",
        "* CNN for pneumonia segmentation: https://bit.ly/2VQMWk9  (**current tutorial**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56d3oMiMw8Wm"
      },
      "source": [
        "# Environment\n",
        "\n",
        "The following lines of code will configure your Google Colab environment for this tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDy5-hb4vpVF"
      },
      "source": [
        "### Enable GPU runtime\n",
        "\n",
        "Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n",
        "\n",
        "```\n",
        "Runtime > Change runtime type > Hardware accelerator > GPU\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcSbeRlEvpVI"
      },
      "source": [
        "### Jarvis library\n",
        "\n",
        "In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfFNUF82vpVK"
      },
      "source": [
        "# --- Install Jarvis library\n",
        "% pip install jarvis-md"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnL47mGKvpVM"
      },
      "source": [
        "### Imports\n",
        "\n",
        "Use the following lines to import any needed libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEocrGo-vpVR"
      },
      "source": [
        "import numpy as np, pandas as pd\n",
        "from tensorflow import losses, optimizers\n",
        "from tensorflow.keras import Input, Model, models, layers, metrics\n",
        "from jarvis.train import datasets, custom\n",
        "from jarvis.utils.display import imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUkAD42PvpVZ"
      },
      "source": [
        "# Data\n",
        "\n",
        "The data used in this tutorial will consist of (frontal projection) chest radiographs from a subset of the RSNA / Kaggle pneumonia challenge (https://www.kaggle.com/c/rsna-pneumonia-detection-challenge). From the complete cohort, a random subset of 1,000 exams will be used for training and evaluation.\n",
        "\n",
        "### Download\n",
        "\n",
        "The custom `datasets.download(...)` method can be used to download a local copy of the dataset. By default the dataset will be archived at `/data/raw/xr_pna`; as needed an alternate location may be specified using `datasets.download(name=..., path=...)`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArdFEwDFvpVg"
      },
      "source": [
        "# --- Download dataset\n",
        "datasets.download(name='xr/pna-512')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChHRifmmvpVn"
      },
      "source": [
        "### Python generators\n",
        "\n",
        "Once the dataset is downloaded locally, Python generators to iterate through the dataset can be easily prepared using the `datasets.prepare(...)` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4PpO5v0vpVq"
      },
      "source": [
        "# --- Prepare generators\n",
        "gen_train, gen_valid, client = datasets.prepare(name='xr/pna-512', keyword='seg-512')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDyHoKF_vpVr"
      },
      "source": [
        "The created generators, `gen_train` and `gen_valid`, are designed to yield two variables per iteration: `xs` and `ys`. Both `xs` and `ys` each represent a dictionary of NumPy arrays containing model input(s) and output(s) for a single *batch* of training. The use of Python generators provides a generic interface for data input for a number of machine learning libraries including Tensorflow 2.0 / Keras.\n",
        "\n",
        "Note that any valid Python iterable method can be used to loop through the generators indefinitely. For example the Python built-in `next(...)` method will yield the next batch of data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiBeft0lvpVy"
      },
      "source": [
        "# --- Yield one example\n",
        "xs, ys = next(gen_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-DlmcS5vpV3"
      },
      "source": [
        "### Data exploration\n",
        "\n",
        "To help facilitate algorithm design, each original chest radiograph has been resampled to a uniform `(512, 512)` matrix. Overall, the dataset comprises a total of `1,000` 2D images: a total of `500` negaative exams and `500` positive exams."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtFyWg-FvpV7"
      },
      "source": [
        "### `xs` dictionary\n",
        "\n",
        "The `xs` dictionary contains a single batch of model inputs:\n",
        "\n",
        "1. `dat`: input chest radiograph resampled to `(1, 512, 512, 1)` matrix shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68qlizpWvpV7"
      },
      "source": [
        "# --- Print keys \n",
        "for key, arr in xs.items():\n",
        "    print('xs key: {} | shape = {}'.format(key.ljust(8), arr.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv1NZxOTvpV9"
      },
      "source": [
        "### `ys` dictionary\n",
        "\n",
        "The `ys` dictionary contains a single batch of model outputs:\n",
        "\n",
        "1. `pna`: output segmentation mask for pneumonia equal in size to the input `(1, 512, 512, 1)` matrix shape\n",
        "\n",
        "* 0 = pixels negative for pneumonia\n",
        "* 1 = pixels positive for pneumonia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLroXDvnvpV-"
      },
      "source": [
        "# --- Print keys \n",
        "for key, arr in ys.items():\n",
        "    print('ys key: {} | shape = {}'.format(key.ljust(8), arr.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haoxRUcWvpWA"
      },
      "source": [
        "### Visualization\n",
        "\n",
        "Use the following lines of code to visualize a single input image and mask using the `imshow(...)` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrxVPeLYvpWA"
      },
      "source": [
        "# --- Show labels\n",
        "xs, ys = next(gen_train)\n",
        "imshow(xs['dat'][0], ys['pna'][0], radius=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNC4oWVRvpWC"
      },
      "source": [
        "Use the following lines of code to visualize an N x N mosaic of all images and masks in the current batch using the `imshow(...)` method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWY-P9pcvpWE"
      },
      "source": [
        "# --- Show \"montage\" of all images\n",
        "xs, ys = next(gen_train)\n",
        "imshow(xs['dat'], ys['pna'], figsize=(12, 12), radius=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KID_bkiTvpWF"
      },
      "source": [
        "### Model inputs\n",
        "\n",
        "For every input in `xs`, a corresponding `Input(...)` variable can be created and returned in a `inputs` dictionary for ease of model development:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTxi45yYvpWI"
      },
      "source": [
        "# --- Create model inputs\n",
        "inputs = client.get_inputs(Input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oKaJZMavpWI"
      },
      "source": [
        "In this example, the equivalent Python code to generate `inputs` would be:\n",
        "\n",
        "```python\n",
        "inputs = {}\n",
        "inputs['dat'] = Input(shape=(1, 512, 512, 1))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3ShPnrZvpWI"
      },
      "source": [
        "# U-Net Architecture\n",
        "\n",
        "The **U-Net** architecture is a common fully-convolutional neural network used to perform instance segmentation. The network topology comprises of symmetric contracting and expanding arms to map an original input image to an output segmentation mask that appoximates the size of the original image:\n",
        "\n",
        "![U-Net Architecture](https://raw.githubusercontent.com/peterchang77/dl_tutor/master/cs190/spring_2020/notebooks/organ_segmentation/pngs/u-net-architecture.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JltDJb1uvpWJ"
      },
      "source": [
        "# Contracting Layers\n",
        "\n",
        "The contracting layers of a U-Net architecture are essentially identical to a standard feed-forward CNN. Compared to the original architecture above, several key modifications will be made for ease of implementation and to optimize for medical imaging tasks including:\n",
        "\n",
        "* same padding (vs. valid padding)\n",
        "* strided convoltions (vs. max-pooling)\n",
        "* smaller filters (channel depths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KcJ5p3CvpWJ"
      },
      "source": [
        "Let us start by defining the contracting layer architecture below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wf2zGMJvpWK"
      },
      "source": [
        "# --- Define kwargs dictionary\n",
        "kwargs = {\n",
        "    'kernel_size': (1, 3, 3),\n",
        "    'padding': 'same'}\n",
        "\n",
        "# --- Define lambda functions\n",
        "conv = lambda x, filters, strides : layers.Conv3D(filters=filters, strides=strides, **kwargs)(x)\n",
        "norm = lambda x : layers.BatchNormalization()(x)\n",
        "relu = lambda x : layers.ReLU()(x)\n",
        "\n",
        "# --- Define stride-1, stride-2 blocks\n",
        "conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n",
        "conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(1, 2, 2))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZXE-An_vpWL"
      },
      "source": [
        "Using these lambda functions, let us define a simple 9-layer contracting network topology with a total a four subsample (stride-2 convolution) operations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEGx-AhDvpWL"
      },
      "source": [
        "# --- Define contracting layers\n",
        "l1 = conv1(16, inputs['dat'])\n",
        "l2 = conv1(32, conv2(32, l1))\n",
        "l3 = conv1(48, conv2(48, l2))\n",
        "l4 = conv1(64, conv2(64, l3))\n",
        "l5 = conv1(80, conv2(80, l4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Cx4sO0wvpWL"
      },
      "source": [
        "**Checkpoint**: What is the shape of the `l5` feature map?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BotXignovpWL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYaszKWvvpWL"
      },
      "source": [
        "# Expanding Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH9i_CRuvpWL"
      },
      "source": [
        "The expanding layers are simply implemented by reversing the operations found in the contract layers above. Specifically, each subsample operation is now replaced by a **convolutional transpose**. Due to the use of **same** padding, defining a transpose operation with the exact same parameters as a strided convolution will ensure that layers in the expanding pathway will exactly match the shape of the corresponding contracting layer.\n",
        "\n",
        "### Convolutional transpose\n",
        "\n",
        "Let us start by defining an additional lambda function for the convolutional transpose:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig5vKp-0vpWM"
      },
      "source": [
        "# --- Define single transpose\n",
        "tran = lambda x, filters, strides : layers.Conv3DTranspose(filters=filters, strides=strides, **kwargs)(x)\n",
        "\n",
        "# --- Define transpose block\n",
        "tran2 = lambda filters, x : relu(norm(tran(x, filters, strides=(1, 2, 2))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMlH1CejvpWN"
      },
      "source": [
        "Carefully compare these functions to the single `conv` operations as well as the `conv1` and `conv2` blocks above. Notice that they share the exact same configurations.\n",
        "\n",
        "Let us now apply the first convolutional transpose block to the `l5` feature map:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgpluDu3vpWO"
      },
      "source": [
        "# --- Define expanding layers\n",
        "l6 = tran2(64, l5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4noJUVEEvpWO"
      },
      "source": [
        "**Checkpoint**: What is the shape of the `l6` feature map?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHNd25PzvpWP"
      },
      "source": [
        "### Concatenation\n",
        "\n",
        "The first connection in this specific U-Net derived architecture is a link between the `l4` and the `l6` layers:\n",
        "\n",
        "```\n",
        "l1 -------------------> l9\n",
        "  \\                    /\n",
        "   l2 -------------> l8\n",
        "     \\              /   \n",
        "      l3 -------> l7\n",
        "        \\        /\n",
        "         l4 -> l6\n",
        "           \\  /\n",
        "            l5\n",
        "```\n",
        "\n",
        "To mediate the first connection between contracting and expanding layers, we must ensure that `l4` and `l6` match in feature map size (the number of filters / channel depth *do not* necessarily). Using the `same` padding as above should ensure that this is the case and thus simplifies the connection operation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-iF7nUmvpWP"
      },
      "source": [
        "# --- Ensure shapes match\n",
        "print(l4.shape)\n",
        "print(l6.shape)\n",
        "\n",
        "# --- Concatenate\n",
        "concat = lambda a, b : layers.Concatenate()([a, b])\n",
        "concat(l4, l6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5eEaYFvvpWP"
      },
      "source": [
        "Note that since `l4` and `l6` are **exactly the same shape** (including matching channel depth), what additional operation could be used here instead of a concatenation?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1H0823_vpWP"
      },
      "source": [
        "### Full expansion\n",
        "\n",
        "Alternate the use of `conv1` and `tran2` blocks to build the remainder of the expanding pathway:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgwH5dgWvpWQ"
      },
      "source": [
        "# --- Define expanding layers\n",
        "l7 = tran2(48, conv1(64, concat(l4, l6)))\n",
        "l8 = tran2(32, conv1(48, concat(l3, l7)))\n",
        "l9 = tran2(16,  conv1(32, concat(l2, l8)))\n",
        "l10 = conv1(16, l9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAcFVDiPvpWS"
      },
      "source": [
        "# Logits\n",
        "\n",
        "The last convolution projects the `l10` feature map into a total of just `n` feature maps, one for each possible class prediction. In this 2-class prediction task, a total of `2` feature maps will be needed. Recall that these feature maps essentially act as a set of **logit scores** for each voxel location throughout the image. As with a standard CNN architecture, **do not** use an activation here in the final convolution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ4E8NYSvpWT"
      },
      "source": [
        "# --- Create logits\n",
        "logits = {}\n",
        "logits['pna'] = layers.Conv3D(filters=2, name='pna', **kwargs)(l10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7knAqtAvpWT"
      },
      "source": [
        "# Model\n",
        "\n",
        "Let us first create our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6DX6YTNvpWT"
      },
      "source": [
        "# --- Create model\n",
        "model = Model(inputs=inputs, outputs=logits)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvJM5yk4vpWT"
      },
      "source": [
        "### Custom Dice score metric\n",
        "\n",
        "The metric of choice for tracking performance of a medical image segmentation algorithm is the **Dice score**. The Dice score is not a default metric built in the Tensorflow library, however a custom metric is available for your convenience as part of the `jarvis-md` package. It is invoked using the `custom.dsc(cls=...)` call, where the argument `cls` refers to the number of *non-zero* classes to track (e.g. the background Dice score is typically not tracked). In this exercise, it will be important to track the performance of segmentation for **pneumonia** (class = 1) only, thus set the `cls` argument to `1`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Niit_A0zvpWT"
      },
      "source": [
        "# --- Compile model\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=2e-4),\n",
        "    loss={'pna': losses.SparseCategoricalCrossentropy(from_logits=True)},\n",
        "    metrics={'pna': custom.dsc(cls=1)},\n",
        "    experimental_run_tf_function=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2BS9O6cvpWU"
      },
      "source": [
        "# Model Training\n",
        "\n",
        "### In-Memory Data\n",
        "\n",
        "The following line of code will load all training data into RAM memory. This strategy can be effective for increasing speed of training for small to medium-sized datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YlLT6ojvpWU"
      },
      "source": [
        "# --- Load data into memory\n",
        "client.load_data_in_memory()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDSy6DnDvpWU"
      },
      "source": [
        "### Training\n",
        "\n",
        "Once the model has been compiled and the data prepared (via a generator), training can be invoked using the `model.fit(...)` method. Ensure that both the training and validation data generators are used. In this particular example, we are defining arbitrary epochs of 100 steps each. Training will proceed for 8 epochs in total. Validation statistics will be assess every fourth epoch. As needed, tune these arugments as need."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9G-Xu2avpWU"
      },
      "source": [
        "model.fit(\n",
        "    x=gen_train, \n",
        "    steps_per_epoch=100, \n",
        "    epochs=8,\n",
        "    validation_data=gen_valid,\n",
        "    validation_steps=100,\n",
        "    validation_freq=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRiSQPyjvpWU"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "To test the trained model, the following steps are required:\n",
        "\n",
        "* load data\n",
        "* use `model.predict(...)` to obtain logit scores\n",
        "* use `np.argmax(...)` to obtain prediction\n",
        "* compare prediction with ground-truth\n",
        "\n",
        "Recall that the generator used to train the model simply iterates through the dataset randomly. For model evaluation, the cohort must instead be loaded manually in an orderly way. For this tutorial, we will create new **test mode** data generators, which will simply load each example individually once for testing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysz9AF2kvpWU"
      },
      "source": [
        "# --- Create validation generator\n",
        "test_train, test_valid = client.create_generators(test=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjSEOO_SvpWV"
      },
      "source": [
        "### Dice score\n",
        "\n",
        "While the Dice score metric for Tensorflow has been provided already, an implementation must still be used to manually calculate the performance during validation. Use the following code cell block to implement:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEuqS7V-vpWV"
      },
      "source": [
        "def dice(y_true, y_pred, c=1, epsilon=1):\n",
        "    \"\"\"\n",
        "    Method to calculate the Dice score coefficient for given class\n",
        "    \n",
        "    :params\n",
        "    \n",
        "      (np.ndarray) y_true : ground-truth label\n",
        "      (np.ndarray) y_pred : predicted logits scores\n",
        "      (int)             c : class to calculate DSC on\n",
        "    \n",
        "    \"\"\"\n",
        "    assert y_true.ndim == y_pred.ndim\n",
        "    \n",
        "    true = y_true[..., 0] == c\n",
        "    pred = np.argmax(y_pred, axis=-1) == c \n",
        "\n",
        "    A = np.count_nonzero(true & pred) * 2\n",
        "    B = np.count_nonzero(true) + np.count_nonzero(pred) + epsilon\n",
        "    \n",
        "    return A / B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K-xl6uMvpWZ"
      },
      "source": [
        "Use the following lines of code to loop through the test set generator and run model prediction on each example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eRKIwmFvpWZ"
      },
      "source": [
        "# --- Test model\n",
        "dsc = []\n",
        "\n",
        "for x, y in test_valid:\n",
        "    \n",
        "    if y['pna'].any():\n",
        "        \n",
        "        # --- Predict\n",
        "        logits = model.predict(x['dat'])\n",
        "\n",
        "        if type(logits) is dict:\n",
        "            logits = logits['pna']\n",
        "\n",
        "        # --- Argmax\n",
        "        dsc.append(dice(y['pna'][0], logits[0], c=1))\n",
        "\n",
        "dsc = np.array(dsc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2heHGcZ0vpWa"
      },
      "source": [
        "Use the following lines of code to calculate validataion cohort performance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJoRM1YkvpWa"
      },
      "source": [
        "# --- Calculate accuracy\n",
        "print('{}: {:0.5f}'.format('Mean Dice'.ljust(20), np.mean(dsc)))\n",
        "print('{}: {:0.5f}'.format('Median Dice'.ljust(20), np.median(dsc)))\n",
        "print('{}: {:0.5f}'.format('25th-centile Dice'.ljust(20), np.percentile(dsc, 25)))\n",
        "print('{}: {:0.5f}'.format('74th-centile Dice'.ljust(20), np.percentile(dsc, 75)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO6vVUjgvpWc"
      },
      "source": [
        "## Saving and Loading a Model\n",
        "\n",
        "After a model has been successfully trained, it can be saved and/or loaded by simply using the `model.save()` and `models.load_model()` methods. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lI21ceyvpWc"
      },
      "source": [
        "# --- Serialize a model\n",
        "model.save('./cnn.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMPVYS22vpWc"
      },
      "source": [
        "# --- Load a serialized model\n",
        "del model\n",
        "model = models.load_model('./cnn.hdf5', compile=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}